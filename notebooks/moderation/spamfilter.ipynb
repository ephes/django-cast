{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99dbab7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa1472a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"import re\\n\\nfrom collections import defaultdict\\n\\n\\ndef split_tokenize(message):\\n    return message.split()\\n\\n\\ntoken_pattern = re.compile(r\\\"(?u)\\\\b\\\\w\\\\w+\\\\b\\\")\\nstandard_tokenizer = token_pattern.findall\\n\\n\\ndef tokenize(message):\\n    return standard_tokenizer(message.lower())\\n\\n\\nclass NaiveBayes:\\n    def __init__(self, tokenize=tokenize):\\n        self.tokenize = tokenize\\n\\n    def get_label_counts(self, messages):\\n        label_counts = defaultdict(int)\\n        for label, text in messages:\\n            label_counts[label] += 1\\n        return label_counts\\n\\n    def get_prior_probabilities(self, label_counts):\\n        number_of_messages = sum(label_counts.values())\\n        return {\\n            label: count / number_of_messages for label, count in label_counts.items()\\n        }\\n\\n    def get_word_label_counts(self, messages):\\n        counts = defaultdict(lambda: defaultdict(int))\\n        for label, text in messages:\\n            for word in self.tokenize(text):\\n                counts[word][label] += 1\\n        return counts\\n\\n    def get_number_of_words(self, word_label_counts):\\n        number_of_words = defaultdict(int)\\n        for word, counts in word_label_counts.items():\\n            for label, count in counts.items():\\n                number_of_words[label] += 1\\n        return number_of_words\\n\\n    def fit(self, messages):\\n        self.prior_probabilities = self.get_prior_probabilities(\\n            self.get_label_counts(messages)\\n        )\\n        self.word_label_counts = self.get_word_label_counts(messages)\\n        self.number_of_words = self.get_number_of_words(self.word_label_counts)\\n        return self\\n\\n    def update_probabilities(self, probabilities, counts_per_label, number_of_words):\\n        updated_probabilites = {}\\n        for label, prior_probability in probabilities.items():\\n            word_count = counts_per_label.get(label, 0.5)\\n            word_probability = word_count / number_of_words[label]\\n            updated_probabilites[label] = prior_probability * word_probability\\n        return updated_probabilites\\n\\n    def normalize(self, probabilities):\\n        factor = 1.0 / float(sum(probabilities.values()))\\n        for name, value in probabilities.items():\\n            probabilities[name] *= factor\\n        return probabilities    \\n\\n    def predict(self, message):\\n        probabilities = dict(self.prior_probabilities)\\n        for word in self.tokenize(message):\\n            counts_per_label = self.word_label_counts.get(word, {})\\n            probabilities = self.update_probabilities(\\n                probabilities, counts_per_label, self.number_of_words\\n            )\\n            probabilities = self.normalize(probabilities)\\n        return probabilities\\n\\n    def predict_label(self, message):\\n        probabilities = self.predict(message)\\n        return sorted(\\n            [(prob, label) for label, prob in probabilities.items()], reverse=True\\n        )[0][1]\";\n",
       "                var nbb_formatted_code = \"import re\\n\\nfrom collections import defaultdict\\n\\n\\ndef split_tokenize(message):\\n    return message.split()\\n\\n\\ntoken_pattern = re.compile(r\\\"(?u)\\\\b\\\\w\\\\w+\\\\b\\\")\\nstandard_tokenizer = token_pattern.findall\\n\\n\\ndef tokenize(message):\\n    return standard_tokenizer(message.lower())\\n\\n\\nclass NaiveBayes:\\n    def __init__(self, tokenize=tokenize):\\n        self.tokenize = tokenize\\n\\n    def get_label_counts(self, messages):\\n        label_counts = defaultdict(int)\\n        for label, text in messages:\\n            label_counts[label] += 1\\n        return label_counts\\n\\n    def get_prior_probabilities(self, label_counts):\\n        number_of_messages = sum(label_counts.values())\\n        return {\\n            label: count / number_of_messages for label, count in label_counts.items()\\n        }\\n\\n    def get_word_label_counts(self, messages):\\n        counts = defaultdict(lambda: defaultdict(int))\\n        for label, text in messages:\\n            for word in self.tokenize(text):\\n                counts[word][label] += 1\\n        return counts\\n\\n    def get_number_of_words(self, word_label_counts):\\n        number_of_words = defaultdict(int)\\n        for word, counts in word_label_counts.items():\\n            for label, count in counts.items():\\n                number_of_words[label] += 1\\n        return number_of_words\\n\\n    def fit(self, messages):\\n        self.prior_probabilities = self.get_prior_probabilities(\\n            self.get_label_counts(messages)\\n        )\\n        self.word_label_counts = self.get_word_label_counts(messages)\\n        self.number_of_words = self.get_number_of_words(self.word_label_counts)\\n        return self\\n\\n    def update_probabilities(self, probabilities, counts_per_label, number_of_words):\\n        updated_probabilites = {}\\n        for label, prior_probability in probabilities.items():\\n            word_count = counts_per_label.get(label, 0.5)\\n            word_probability = word_count / number_of_words[label]\\n            updated_probabilites[label] = prior_probability * word_probability\\n        return updated_probabilites\\n\\n    def normalize(self, probabilities):\\n        factor = 1.0 / float(sum(probabilities.values()))\\n        for name, value in probabilities.items():\\n            probabilities[name] *= factor\\n        return probabilities\\n\\n    def predict(self, message):\\n        probabilities = dict(self.prior_probabilities)\\n        for word in self.tokenize(message):\\n            counts_per_label = self.word_label_counts.get(word, {})\\n            probabilities = self.update_probabilities(\\n                probabilities, counts_per_label, self.number_of_words\\n            )\\n            probabilities = self.normalize(probabilities)\\n        return probabilities\\n\\n    def predict_label(self, message):\\n        probabilities = self.predict(message)\\n        return sorted(\\n            [(prob, label) for label, prob in probabilities.items()], reverse=True\\n        )[0][1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def split_tokenize(message):\n",
    "    return message.split()\n",
    "\n",
    "\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "standard_tokenizer = token_pattern.findall\n",
    "\n",
    "\n",
    "def tokenize(message):\n",
    "    return standard_tokenizer(message.lower())\n",
    "\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, tokenize=tokenize):\n",
    "        self.tokenize = tokenize\n",
    "\n",
    "    def get_label_counts(self, messages):\n",
    "        label_counts = defaultdict(int)\n",
    "        for label, text in messages:\n",
    "            label_counts[label] += 1\n",
    "        return label_counts\n",
    "\n",
    "    def get_prior_probabilities(self, label_counts):\n",
    "        number_of_messages = sum(label_counts.values())\n",
    "        return {\n",
    "            label: count / number_of_messages for label, count in label_counts.items()\n",
    "        }\n",
    "\n",
    "    def get_word_label_counts(self, messages):\n",
    "        counts = defaultdict(lambda: defaultdict(int))\n",
    "        for label, text in messages:\n",
    "            for word in self.tokenize(text):\n",
    "                counts[word][label] += 1\n",
    "        return counts\n",
    "\n",
    "    def get_number_of_words(self, word_label_counts):\n",
    "        number_of_words = defaultdict(int)\n",
    "        for word, counts in word_label_counts.items():\n",
    "            for label, count in counts.items():\n",
    "                number_of_words[label] += 1\n",
    "        return number_of_words\n",
    "\n",
    "    def fit(self, messages):\n",
    "        self.prior_probabilities = self.get_prior_probabilities(\n",
    "            self.get_label_counts(messages)\n",
    "        )\n",
    "        self.word_label_counts = self.get_word_label_counts(messages)\n",
    "        self.number_of_words = self.get_number_of_words(self.word_label_counts)\n",
    "        return self\n",
    "\n",
    "    def update_probabilities(self, probabilities, counts_per_label, number_of_words):\n",
    "        updated_probabilites = {}\n",
    "        for label, prior_probability in probabilities.items():\n",
    "            word_count = counts_per_label.get(label, 0.5)\n",
    "            word_probability = word_count / number_of_words[label]\n",
    "            updated_probabilites[label] = prior_probability * word_probability\n",
    "        return updated_probabilites\n",
    "\n",
    "    def normalize(self, probabilities):\n",
    "        factor = 1.0 / float(sum(probabilities.values()))\n",
    "        for name, value in probabilities.items():\n",
    "            probabilities[name] *= factor\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, message):\n",
    "        probabilities = dict(self.prior_probabilities)\n",
    "        for word in self.tokenize(message):\n",
    "            counts_per_label = self.word_label_counts.get(word, {})\n",
    "            probabilities = self.update_probabilities(\n",
    "                probabilities, counts_per_label, self.number_of_words\n",
    "            )\n",
    "            probabilities = self.normalize(probabilities)\n",
    "        return probabilities\n",
    "\n",
    "    def predict_label(self, message):\n",
    "        probabilities = self.predict(message)\n",
    "        return sorted(\n",
    "            [(prob, label) for label, prob in probabilities.items()], reverse=True\n",
    "        )[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8210730",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/35/mhty_0hd42ddfvyk3_09f1hc0000gn/T/ipykernel_15417/4210428974.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtest_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/35/mhty_0hd42ddfvyk3_09f1hc0000gn/T/ipykernel_15417/4210428974.py\u001b[0m in \u001b[0;36mtest_predict\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_probabilites\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_probabilites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"def test_predict():\\n    train = [\\n        (\\\"spam\\\", \\\"foo bar baz\\\"),\\n        (\\\"spam\\\", \\\"foo asdf bsdf\\\"),\\n        (\\\"ham\\\", \\\"asdf csdf\\\"),\\n    ]\\n    test_cases = [\\n        # message, expected_probabilities\\n        (\\\"foo\\\", {\\\"ham\\\": (1 / 3) * (0.5 / 2), \\\"spam\\\": (2 / 3) * (2 / 5)})\\n    ]\\n    model = NaiveBayes().fit(train)\\n    for message, expected_probabilites in test_cases:\\n        probabilities = model.predict(message)\\n        assert probabilities == expected_probabilites\\n\\n\\ntest_predict()\";\n",
       "                var nbb_formatted_code = \"def test_predict():\\n    train = [\\n        (\\\"spam\\\", \\\"foo bar baz\\\"),\\n        (\\\"spam\\\", \\\"foo asdf bsdf\\\"),\\n        (\\\"ham\\\", \\\"asdf csdf\\\"),\\n    ]\\n    test_cases = [\\n        # message, expected_probabilities\\n        (\\\"foo\\\", {\\\"ham\\\": (1 / 3) * (0.5 / 2), \\\"spam\\\": (2 / 3) * (2 / 5)})\\n    ]\\n    model = NaiveBayes().fit(train)\\n    for message, expected_probabilites in test_cases:\\n        probabilities = model.predict(message)\\n        assert probabilities == expected_probabilites\\n\\n\\ntest_predict()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_predict():\n",
    "    train = [\n",
    "        (\"spam\", \"foo bar baz\"),\n",
    "        (\"spam\", \"foo asdf bsdf\"),\n",
    "        (\"ham\", \"asdf csdf\"),\n",
    "    ]\n",
    "    test_cases = [\n",
    "        # message, expected_probabilities\n",
    "        (\"foo\", {\"ham\": (1 / 3) * (0.5 / 2), \"spam\": (2 / 3) * (2 / 5)})\n",
    "    ]\n",
    "    model = NaiveBayes().fit(train)\n",
    "    for message, expected_probabilites in test_cases:\n",
    "        probabilities = model.predict(message)\n",
    "        assert probabilities == expected_probabilites\n",
    "\n",
    "\n",
    "test_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df730d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"def test_predict_word_probabilities():\\n    test_cases = [\\n        # (probabilities, counts_per_label, number_of_words), expected\\n        (({}, {}, {}), {}),\\n        (({\\\"spam\\\": 1}, {\\\"spam\\\": 10}, {\\\"spam\\\": 100}), {\\\"spam\\\": 0.1}),\\n        (\\n            ({\\\"spam\\\": 1, \\\"ham\\\": 0.5}, {\\\"spam\\\": 10, \\\"ham\\\": 5}, {\\\"spam\\\": 100, \\\"ham\\\": 50}),\\n            {\\\"spam\\\": 0.1, \\\"ham\\\": 0.05},\\n        ),\\n        # no word count -> make sure probability is > 0\\n        (({\\\"spam\\\": 1}, {}, {\\\"spam\\\": 100}), {\\\"spam\\\": 0.005}),\\n    ]\\n    model = NaiveBayes()\\n    for (probabilities, counts_per_label, number_of_words), expected in test_cases:\\n        updated = model.update_probabilities(\\n            probabilities, counts_per_label, number_of_words\\n        )\\n        assert updated == expected\\n\\n\\ntest_predict_word_probabilities()\";\n",
       "                var nbb_formatted_code = \"def test_predict_word_probabilities():\\n    test_cases = [\\n        # (probabilities, counts_per_label, number_of_words), expected\\n        (({}, {}, {}), {}),\\n        (({\\\"spam\\\": 1}, {\\\"spam\\\": 10}, {\\\"spam\\\": 100}), {\\\"spam\\\": 0.1}),\\n        (\\n            ({\\\"spam\\\": 1, \\\"ham\\\": 0.5}, {\\\"spam\\\": 10, \\\"ham\\\": 5}, {\\\"spam\\\": 100, \\\"ham\\\": 50}),\\n            {\\\"spam\\\": 0.1, \\\"ham\\\": 0.05},\\n        ),\\n        # no word count -> make sure probability is > 0\\n        (({\\\"spam\\\": 1}, {}, {\\\"spam\\\": 100}), {\\\"spam\\\": 0.005}),\\n    ]\\n    model = NaiveBayes()\\n    for (probabilities, counts_per_label, number_of_words), expected in test_cases:\\n        updated = model.update_probabilities(\\n            probabilities, counts_per_label, number_of_words\\n        )\\n        assert updated == expected\\n\\n\\ntest_predict_word_probabilities()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_predict_word_probabilities():\n",
    "    test_cases = [\n",
    "        # (probabilities, counts_per_label, number_of_words), expected\n",
    "        (({}, {}, {}), {}),\n",
    "        (({\"spam\": 1}, {\"spam\": 10}, {\"spam\": 100}), {\"spam\": 0.1}),\n",
    "        (\n",
    "            ({\"spam\": 1, \"ham\": 0.5}, {\"spam\": 10, \"ham\": 5}, {\"spam\": 100, \"ham\": 50}),\n",
    "            {\"spam\": 0.1, \"ham\": 0.05},\n",
    "        ),\n",
    "        # no word count -> make sure probability is > 0\n",
    "        (({\"spam\": 1}, {}, {\"spam\": 100}), {\"spam\": 0.005}),\n",
    "    ]\n",
    "    model = NaiveBayes()\n",
    "    for (probabilities, counts_per_label, number_of_words), expected in test_cases:\n",
    "        updated = model.update_probabilities(\n",
    "            probabilities, counts_per_label, number_of_words\n",
    "        )\n",
    "        assert updated == expected\n",
    "\n",
    "\n",
    "test_predict_word_probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf7957d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"def test_initial_probabilities():\\n    test_cases = [\\n        # (train, expected_initial_probabilities)\\n        ([], {}),\\n        ([(\\\"ham\\\", \\\"\\\"), (\\\"spam\\\", \\\"\\\")], {\\\"ham\\\": 0.5, \\\"spam\\\": 0.5}),\\n        ([(i, \\\"\\\") for i in range(3)], {k: 1 / 3 for k in range(3)}),\\n    ]\\n    for train, expected_initial_probabilities in test_cases:\\n        model = NaiveBayes().fit(train)\\n        probabilities = model.predict(\\\"\\\")\\n        assert probabilities == expected_initial_probabilities\\n\\n\\ntest_initial_probabilities()\";\n",
       "                var nbb_formatted_code = \"def test_initial_probabilities():\\n    test_cases = [\\n        # (train, expected_initial_probabilities)\\n        ([], {}),\\n        ([(\\\"ham\\\", \\\"\\\"), (\\\"spam\\\", \\\"\\\")], {\\\"ham\\\": 0.5, \\\"spam\\\": 0.5}),\\n        ([(i, \\\"\\\") for i in range(3)], {k: 1 / 3 for k in range(3)}),\\n    ]\\n    for train, expected_initial_probabilities in test_cases:\\n        model = NaiveBayes().fit(train)\\n        probabilities = model.predict(\\\"\\\")\\n        assert probabilities == expected_initial_probabilities\\n\\n\\ntest_initial_probabilities()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_initial_probabilities():\n",
    "    test_cases = [\n",
    "        # (train, expected_initial_probabilities)\n",
    "        ([], {}),\n",
    "        ([(\"ham\", \"\"), (\"spam\", \"\")], {\"ham\": 0.5, \"spam\": 0.5}),\n",
    "        ([(i, \"\") for i in range(3)], {k: 1 / 3 for k in range(3)}),\n",
    "    ]\n",
    "    for train, expected_initial_probabilities in test_cases:\n",
    "        model = NaiveBayes().fit(train)\n",
    "        probabilities = model.predict(\"\")\n",
    "        assert probabilities == expected_initial_probabilities\n",
    "\n",
    "\n",
    "test_initial_probabilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476777ad",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5cb9d6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"import random\\n\\nrandom.seed(2021)  # make sure the same messages are choosen between restarts\\n\\n\\ndef split_train_test(messages, test_quote=0.1):\\n    messages_by_label = defaultdict(list)\\n    for label, text in messages:\\n        messages_by_label[label].append((label, text))\\n\\n    # stratified sampling\\n    test, train = [], []\\n    for label, label_messages in messages_by_label.items():\\n        indices = list(range(len(label_messages)))\\n        test_len = int(len(indices) * test_quote)\\n        test_indices = set(random.sample(indices, test_len))\\n        for index, message in enumerate(label_messages):\\n            if index in test_indices:\\n                test.append(message)\\n            else:\\n                train.append(message)\\n    return train, test\";\n",
       "                var nbb_formatted_code = \"import random\\n\\nrandom.seed(2021)  # make sure the same messages are choosen between restarts\\n\\n\\ndef split_train_test(messages, test_quote=0.1):\\n    messages_by_label = defaultdict(list)\\n    for label, text in messages:\\n        messages_by_label[label].append((label, text))\\n\\n    # stratified sampling\\n    test, train = [], []\\n    for label, label_messages in messages_by_label.items():\\n        indices = list(range(len(label_messages)))\\n        test_len = int(len(indices) * test_quote)\\n        test_indices = set(random.sample(indices, test_len))\\n        for index, message in enumerate(label_messages):\\n            if index in test_indices:\\n                test.append(message)\\n            else:\\n                train.append(message)\\n    return train, test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(2021)  # make sure the same messages are choosen between restarts\n",
    "\n",
    "\n",
    "def split_train_test(messages, test_quote=0.1):\n",
    "    messages_by_label = defaultdict(list)\n",
    "    for label, text in messages:\n",
    "        messages_by_label[label].append((label, text))\n",
    "\n",
    "    # stratified sampling\n",
    "    test, train = [], []\n",
    "    for label, label_messages in messages_by_label.items():\n",
    "        indices = list(range(len(label_messages)))\n",
    "        test_len = int(len(indices) * test_quote)\n",
    "        test_indices = set(random.sample(indices, test_len))\n",
    "        for index, message in enumerate(label_messages):\n",
    "            if index in test_indices:\n",
    "                test.append(message)\n",
    "            else:\n",
    "                train.append(message)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8ab94dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"from django_comments import get_model as get_comments_model\\n\\nComment = get_comments_model()\\n\\n\\ndef get_messages_from_comments():\\n    messages = []\\n    for comment in Comment.objects.all():\\n        label = \\\"spam\\\" if comment.is_removed else \\\"ham\\\"\\n        message = f\\\"{comment.name} {comment.title} {comment.comment}\\\"\\n        messages.append((label, message))\\n    return messages\\n\\n\\nmessages = get_messages_from_comments()\";\n",
       "                var nbb_formatted_code = \"from django_comments import get_model as get_comments_model\\n\\nComment = get_comments_model()\\n\\n\\ndef get_messages_from_comments():\\n    messages = []\\n    for comment in Comment.objects.all():\\n        label = \\\"spam\\\" if comment.is_removed else \\\"ham\\\"\\n        message = f\\\"{comment.name} {comment.title} {comment.comment}\\\"\\n        messages.append((label, message))\\n    return messages\\n\\n\\nmessages = get_messages_from_comments()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from django_comments import get_model as get_comments_model\n",
    "\n",
    "Comment = get_comments_model()\n",
    "\n",
    "\n",
    "def get_messages_from_comments():\n",
    "    messages = []\n",
    "    for comment in Comment.objects.all():\n",
    "        label = \"spam\" if comment.is_removed else \"ham\"\n",
    "        message = f\"{comment.name} {comment.title} {comment.comment}\"\n",
    "        messages.append((label, message))\n",
    "    return messages\n",
    "\n",
    "\n",
    "messages = get_messages_from_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21b9964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 34\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"train_messages, test_messages = split_train_test(messages, test_quote=0.1)\\nprint(len(train_messages), len(test_messages))\\nmodel = NaiveBayes().fit(train_messages)\";\n",
       "                var nbb_formatted_code = \"train_messages, test_messages = split_train_test(messages, test_quote=0.1)\\nprint(len(train_messages), len(test_messages))\\nmodel = NaiveBayes().fit(train_messages)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_messages, test_messages = split_train_test(messages, test_quote=0.1)\n",
    "print(len(train_messages), len(test_messages))\n",
    "model = NaiveBayes().fit(train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "983094e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941\n",
      "CPU times: user 17.9 ms, sys: 1.75 ms, total: 19.7 ms\n",
      "Wall time: 18.1 ms\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 68;\n",
       "                var nbb_unformatted_code = \"%%time\\n\\ntrue_positives = 0\\nall_observations = len(test_messages)\\n\\nfor label, message in test_messages:\\n    if model.predict_label(message) == label:\\n        true_positives += 1\\n\\naccuracy = true_positives / all_observations\\nprint(f\\\"Accuracy: {accuracy:.3f}\\\")\";\n",
       "                var nbb_formatted_code = \"%%time\\n\\ntrue_positives = 0\\nall_observations = len(test_messages)\\n\\nfor label, message in test_messages:\\n    if model.predict_label(message) == label:\\n        true_positives += 1\\n\\naccuracy = true_positives / all_observations\\nprint(f\\\"Accuracy: {accuracy:.3f}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "true_positives = 0\n",
    "all_observations = len(test_messages)\n",
    "\n",
    "for label, message in test_messages:\n",
    "    if model.predict_label(message) == label:\n",
    "        true_positives += 1\n",
    "\n",
    "accuracy = true_positives / all_observations\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb397c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"outcomes = ((\\\"true\\\", \\\"false\\\"), (\\\"positive\\\", \\\"negative\\\"))\\npossible_results = [f\\\"{a}_{b}\\\" for b in outcomes[1] for a in outcomes[0]]\\nresult_template = dict.fromkeys(possible_results, 0)\\n\\nlabels = set(model.prior_probabilities.keys())\\nlabel_results = {label: dict(result_template) for label in labels}\\nall_observations = len(test_messages)\\n\\nfor label, message in test_messages:\\n    predicted = model.predict_label(message)\\n    if label == predicted:\\n        label_results[label][\\\"true_positive\\\"] += 1\\n    else:\\n        label_results[label][\\\"false_negative\\\"] += 1\\n        label_results[predicted][\\\"false_positive\\\"] += 1\";\n",
       "                var nbb_formatted_code = \"outcomes = ((\\\"true\\\", \\\"false\\\"), (\\\"positive\\\", \\\"negative\\\"))\\npossible_results = [f\\\"{a}_{b}\\\" for b in outcomes[1] for a in outcomes[0]]\\nresult_template = dict.fromkeys(possible_results, 0)\\n\\nlabels = set(model.prior_probabilities.keys())\\nlabel_results = {label: dict(result_template) for label in labels}\\nall_observations = len(test_messages)\\n\\nfor label, message in test_messages:\\n    predicted = model.predict_label(message)\\n    if label == predicted:\\n        label_results[label][\\\"true_positive\\\"] += 1\\n    else:\\n        label_results[label][\\\"false_negative\\\"] += 1\\n        label_results[predicted][\\\"false_positive\\\"] += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outcomes = ((\"true\", \"false\"), (\"positive\", \"negative\"))\n",
    "possible_results = [f\"{a}_{b}\" for b in outcomes[1] for a in outcomes[0]]\n",
    "result_template = dict.fromkeys(possible_results, 0)\n",
    "\n",
    "labels = set(model.prior_probabilities.keys())\n",
    "label_results = {label: dict(result_template) for label in labels}\n",
    "all_observations = len(test_messages)\n",
    "\n",
    "for label, message in test_messages:\n",
    "    predicted = model.predict_label(message)\n",
    "    if label == predicted:\n",
    "        label_results[label][\"true_positive\"] += 1\n",
    "    else:\n",
    "        label_results[label][\"false_negative\"] += 1\n",
    "        label_results[predicted][\"false_positive\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3581efd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 70;\n",
       "                var nbb_unformatted_code = \"def precision_recall_f1(result):\\n    all_observations = sum(result.values())\\n    tp = result[\\\"true_positive\\\"]\\n    fp = result[\\\"false_positive\\\"]\\n    fn = result[\\\"false_negative\\\"]\\n    precision = tp / (tp + fp)\\n    recall = tp / (tp + fn)\\n    f1 = 2 * (precision * recall) / (precision + recall)\\n    return precision, recall, f1\\n\\n\\ndef show_result(label_results):\\n    for label, result in label_results.items():\\n        precision, recall, f1 = precision_recall_f1(result)\\n        print(\\n            f\\\"{label: >4} f1: {f1:.3f} precision: {precision:.3f} recall: {recall:.3f}\\\"\\n        )\";\n",
       "                var nbb_formatted_code = \"def precision_recall_f1(result):\\n    all_observations = sum(result.values())\\n    tp = result[\\\"true_positive\\\"]\\n    fp = result[\\\"false_positive\\\"]\\n    fn = result[\\\"false_negative\\\"]\\n    precision = tp / (tp + fp)\\n    recall = tp / (tp + fn)\\n    f1 = 2 * (precision * recall) / (precision + recall)\\n    return precision, recall, f1\\n\\n\\ndef show_result(label_results):\\n    for label, result in label_results.items():\\n        precision, recall, f1 = precision_recall_f1(result)\\n        print(\\n            f\\\"{label: >4} f1: {f1:.3f} precision: {precision:.3f} recall: {recall:.3f}\\\"\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def precision_recall_f1(result):\n",
    "    all_observations = sum(result.values())\n",
    "    tp = result[\"true_positive\"]\n",
    "    fp = result[\"false_positive\"]\n",
    "    fn = result[\"false_negative\"]\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def show_result(label_results):\n",
    "    for label, result in label_results.items():\n",
    "        precision, recall, f1 = precision_recall_f1(result)\n",
    "        print(\n",
    "            f\"{label: >4} f1: {f1:.3f} precision: {precision:.3f} recall: {recall:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "269348f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ham f1: 0.900 precision: 0.818 recall: 1.000\n",
      "spam f1: 0.958 precision: 1.000 recall: 0.920\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"show_result(label_results)\";\n",
       "                var nbb_formatted_code = \"show_result(label_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_result(label_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25bfd2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ham f1: 0.900 precision: 0.818 recall: 1.000\n",
      "spam f1: 0.958 precision: 1.000 recall: 0.920\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"show_result(label_results)\";\n",
       "                var nbb_formatted_code = \"show_result(label_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_result(label_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d66f0ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ham f1: 0.987 precision: 0.986 recall: 0.988\n",
      "spam f1: 0.912 precision: 0.918 recall: 0.905\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"show_result(label_results)\";\n",
       "                var nbb_formatted_code = \"show_result(label_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_result(label_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c95522a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ham f1: 0.991 precision: 0.996 recall: 0.985\n",
      "spam f1: 0.941 precision: 0.911 recall: 0.973\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"show_result(label_results)\";\n",
       "                var nbb_formatted_code = \"show_result(label_results)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_result(label_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6aad3908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"import io\\nimport zipfile\\nimport requests\\n\\n\\ndef get_sms_messages():\\n    # download zip archive\\n    training_data_url = (\\n        \\\"https://d2b7dn9rofvhjd.cloudfront.net/sms-spam-collection-dataset.zip\\\"\\n    )\\n    response = requests.get(training_data_url)\\n    z = zipfile.ZipFile(io.BytesIO(response.content))\\n\\n    # parse messages\\n    spam_text = z.read(\\\"spam.csv\\\").decode(\\\"latin1\\\")\\n    lines = iter(spam_text.split(\\\"\\\\r\\\\n\\\"))\\n    skipped = next(lines)  # skip first line\\n\\n    messages = []\\n    for line in lines:\\n        line = line.rstrip(\\\",\\\")\\n        label, *message = line.split(\\\",\\\")\\n        messages.append((label, \\\" \\\".join(message)))\\n    return messages\\n\\n\\nmessages = get_sms_messages()\";\n",
       "                var nbb_formatted_code = \"import io\\nimport zipfile\\nimport requests\\n\\n\\ndef get_sms_messages():\\n    # download zip archive\\n    training_data_url = (\\n        \\\"https://d2b7dn9rofvhjd.cloudfront.net/sms-spam-collection-dataset.zip\\\"\\n    )\\n    response = requests.get(training_data_url)\\n    z = zipfile.ZipFile(io.BytesIO(response.content))\\n\\n    # parse messages\\n    spam_text = z.read(\\\"spam.csv\\\").decode(\\\"latin1\\\")\\n    lines = iter(spam_text.split(\\\"\\\\r\\\\n\\\"))\\n    skipped = next(lines)  # skip first line\\n\\n    messages = []\\n    for line in lines:\\n        line = line.rstrip(\\\",\\\")\\n        label, *message = line.split(\\\",\\\")\\n        messages.append((label, \\\" \\\".join(message)))\\n    return messages\\n\\n\\nmessages = get_sms_messages()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_sms_messages():\n",
    "    # download zip archive\n",
    "    training_data_url = (\n",
    "        \"https://d2b7dn9rofvhjd.cloudfront.net/sms-spam-collection-dataset.zip\"\n",
    "    )\n",
    "    response = requests.get(training_data_url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "    # parse messages\n",
    "    spam_text = z.read(\"spam.csv\").decode(\"latin1\")\n",
    "    lines = iter(spam_text.split(\"\\r\\n\"))\n",
    "    skipped = next(lines)  # skip first line\n",
    "\n",
    "    messages = []\n",
    "    for line in lines:\n",
    "        line = line.rstrip(\",\")\n",
    "        label, *message = line.split(\",\")\n",
    "        messages.append((label, \" \".join(message)))\n",
    "    return messages\n",
    "\n",
    "\n",
    "messages = get_sms_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d20d6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5016 556\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"train_messages, test_messages = split_train_test(messages, test_quote=0.1)\\nprint(len(train_messages), len(test_messages))\\nmodel = NaiveBayes().fit(train_messages)\";\n",
       "                var nbb_formatted_code = \"train_messages, test_messages = split_train_test(messages, test_quote=0.1)\\nprint(len(train_messages), len(test_messages))\\nmodel = NaiveBayes().fit(train_messages)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_messages, test_messages = split_train_test(messages, test_quote=0.1)\n",
    "print(len(train_messages), len(test_messages))\n",
    "model = NaiveBayes().fit(train_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f0efe",
   "metadata": {},
   "source": [
    "# False Positives Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff81fbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 72;\n",
       "                var nbb_unformatted_code = \"false_positive = \\\"\\\"\\\"\\nHallo,\\n\\nvielen Dank f\\u00fcr den Tipp mit pywin32. Ich nutze auto-py-to-exe damit meine Kollegen nicht erst python installieren m\\u00fcssen. Ich habe ein pip Update gemacht und pl\\u00f6tzlich  konnte ich nicht mehr die exe  Datei nutzen. Ich habe eine erzeugt bekommen. Da es im Visual Studio Code funktioniert hat, habe ich wie immer die alte exe gleich \\u00fcberschrieben. Ich habe drei Stunden geschwitzt um eine funktionierende Version in meinen Ordnern  zu finden. Ich werde es nach meinem Urlaub testen, hoffe euer Tipp funktioniert, da meine Kollegen sonst Python installieren m\\u00fcssen und eine .pyw starten m\\u00fcssen. Bei der exe k\\u00f6nnen sie wenigstens nichts kaputt machen.\\n\\nAlso vielen Dank! Bleibt gesund.\\nToller Podcast auch wenn ich nicht immer alles verstehe. :-)\\n\\nFrage:\\nW\\u00fcrdet ihr Tkinter oder Django empfehlen wenn man ein Cockpit bauen m\\u00f6chte damit die Kollegen damit arbeiten k\\u00f6nnen? Ich habe eure Django Folge zwar geh\\u00f6rt aber war dann fachlich schnell raus. Wir haben keine Netzlaufwerke mehr sondern nur noch Onedrive und Sharepoints. Ich habe ein 3800 Zeilen langes Script geschrieben was tkinter nutzt. Kann man Django einfach so anderen bereitstellen oder ben\\u00f6tigt man einen Server wo das laufen muss? Wenn ja dann muss ich bei tkinter bleiben was auch okay ist aber man will ja das Tool auch optisch anheben. :-)\\n\\nAlso wie gesagt, Dankesch\\u00f6n f\\u00fcr die tollen Folgen, ich lerne immer etwas dazu und heute war es ganz wichtig mit dem pywin32 Hinweis!!!\\n\\\"\\\"\\\"\";\n",
       "                var nbb_formatted_code = \"false_positive = \\\"\\\"\\\"\\nHallo,\\n\\nvielen Dank f\\u00fcr den Tipp mit pywin32. Ich nutze auto-py-to-exe damit meine Kollegen nicht erst python installieren m\\u00fcssen. Ich habe ein pip Update gemacht und pl\\u00f6tzlich  konnte ich nicht mehr die exe  Datei nutzen. Ich habe eine erzeugt bekommen. Da es im Visual Studio Code funktioniert hat, habe ich wie immer die alte exe gleich \\u00fcberschrieben. Ich habe drei Stunden geschwitzt um eine funktionierende Version in meinen Ordnern  zu finden. Ich werde es nach meinem Urlaub testen, hoffe euer Tipp funktioniert, da meine Kollegen sonst Python installieren m\\u00fcssen und eine .pyw starten m\\u00fcssen. Bei der exe k\\u00f6nnen sie wenigstens nichts kaputt machen.\\n\\nAlso vielen Dank! Bleibt gesund.\\nToller Podcast auch wenn ich nicht immer alles verstehe. :-)\\n\\nFrage:\\nW\\u00fcrdet ihr Tkinter oder Django empfehlen wenn man ein Cockpit bauen m\\u00f6chte damit die Kollegen damit arbeiten k\\u00f6nnen? Ich habe eure Django Folge zwar geh\\u00f6rt aber war dann fachlich schnell raus. Wir haben keine Netzlaufwerke mehr sondern nur noch Onedrive und Sharepoints. Ich habe ein 3800 Zeilen langes Script geschrieben was tkinter nutzt. Kann man Django einfach so anderen bereitstellen oder ben\\u00f6tigt man einen Server wo das laufen muss? Wenn ja dann muss ich bei tkinter bleiben was auch okay ist aber man will ja das Tool auch optisch anheben. :-)\\n\\nAlso wie gesagt, Dankesch\\u00f6n f\\u00fcr die tollen Folgen, ich lerne immer etwas dazu und heute war es ganz wichtig mit dem pywin32 Hinweis!!!\\n\\\"\\\"\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "false_positive = \"\"\"\n",
    "Hallo,\n",
    "\n",
    "vielen Dank für den Tipp mit pywin32. Ich nutze auto-py-to-exe damit meine Kollegen nicht erst python installieren müssen. Ich habe ein pip Update gemacht und plötzlich  konnte ich nicht mehr die exe  Datei nutzen. Ich habe eine erzeugt bekommen. Da es im Visual Studio Code funktioniert hat, habe ich wie immer die alte exe gleich überschrieben. Ich habe drei Stunden geschwitzt um eine funktionierende Version in meinen Ordnern  zu finden. Ich werde es nach meinem Urlaub testen, hoffe euer Tipp funktioniert, da meine Kollegen sonst Python installieren müssen und eine .pyw starten müssen. Bei der exe können sie wenigstens nichts kaputt machen.\n",
    "\n",
    "Also vielen Dank! Bleibt gesund.\n",
    "Toller Podcast auch wenn ich nicht immer alles verstehe. :-)\n",
    "\n",
    "Frage:\n",
    "Würdet ihr Tkinter oder Django empfehlen wenn man ein Cockpit bauen möchte damit die Kollegen damit arbeiten können? Ich habe eure Django Folge zwar gehört aber war dann fachlich schnell raus. Wir haben keine Netzlaufwerke mehr sondern nur noch Onedrive und Sharepoints. Ich habe ein 3800 Zeilen langes Script geschrieben was tkinter nutzt. Kann man Django einfach so anderen bereitstellen oder benötigt man einen Server wo das laufen muss? Wenn ja dann muss ich bei tkinter bleiben was auch okay ist aber man will ja das Tool auch optisch anheben. :-)\n",
    "\n",
    "Also wie gesagt, Dankeschön für die tollen Folgen, ich lerne immer etwas dazu und heute war es ganz wichtig mit dem pywin32 Hinweis!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a90dd692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 0.9999999999999999, 'spam': 7.719642281555638e-247}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 73;\n",
       "                var nbb_unformatted_code = \"model.predict(false_positive)\";\n",
       "                var nbb_formatted_code = \"model.predict(false_positive)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.predict(false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "781c8e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 966 µs, sys: 0 ns, total: 966 µs\n",
      "Wall time: 974 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"%%time\\nmodel.predict_label(false_positive)\";\n",
       "                var nbb_formatted_code = \"%%time\\nmodel.predict_label(false_positive)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "model.predict_label(false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c06b27c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"probabilities = dict(model.prior_probabilities)\";\n",
       "                var nbb_formatted_code = \"probabilities = dict(model.prior_probabilities)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probabilities = dict(model.prior_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ad92fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 0.267741935483871, 'spam': 0.7322580645161291}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"probabilities\";\n",
       "                var nbb_formatted_code = \"probabilities\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c65f884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"1.0 / 0.5\";\n",
       "                var nbb_formatted_code = \"1.0 / 0.5\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1.0 / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5400ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"def normalize(probabilities):\\n    factor = 1.0 / float(sum(probabilities.values()))\\n    for name, value in probabilities.items():\\n        probabilities[name] *= factor\\n    return probabilities\";\n",
       "                var nbb_formatted_code = \"def normalize(probabilities):\\n    factor = 1.0 / float(sum(probabilities.values()))\\n    for name, value in probabilities.items():\\n        probabilities[name] *= factor\\n    return probabilities\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalize(probabilities):\n",
    "    factor = 1.0 / float(sum(probabilities.values()))\n",
    "    for name, value in probabilities.items():\n",
    "        probabilities[name] *= factor\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfc0c57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spam': 1.0, 'ham': 0.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"normalize({\\\"spam\\\": 0.2, \\\"ham\\\": 0.0})\";\n",
       "                var nbb_formatted_code = \"normalize({\\\"spam\\\": 0.2, \\\"ham\\\": 0.0})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize({\"spam\": 0.2, \"ham\": 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d190a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spam': 0.6666666666666666, 'ham': 0.3333333333333333}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"normalize({\\\"spam\\\": 0.2, \\\"ham\\\": 0.1})\";\n",
       "                var nbb_formatted_code = \"normalize({\\\"spam\\\": 0.2, \\\"ham\\\": 0.1})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize({\"spam\": 0.2, \"ham\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac7df1a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/35/mhty_0hd42ddfvyk3_09f1hc0000gn/T/ipykernel_15417/1424959247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"spam\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ham\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/35/mhty_0hd42ddfvyk3_09f1hc0000gn/T/ipykernel_15417/3743646651.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(probabilities)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"normalize({\\\"spam\\\": 0.0, \\\"ham\\\": 0.0})\";\n",
       "                var nbb_formatted_code = \"normalize({\\\"spam\\\": 0.0, \\\"ham\\\": 0.0})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize({\"spam\": 0.0, \"ham\": 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a296907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham': 0.0012519662981877735, 'spam': 0.00014757316898753105}\n",
      "hallo {'ham': 0.8945559075333699, 'spam': 0.10544409246663011}\n",
      "{'ham': 0.005378091628457133, 'spam': 2.1250320932412357e-05}\n",
      "vielen {'ham': 0.9960642757707141, 'spam': 0.0039357242292859295}\n",
      "{'ham': 0.006653735977092279, 'spam': 7.931729603558907e-07}\n",
      "dank {'ham': 0.9998808070499849, 'spam': 0.00011919295001504606}\n",
      "{'ham': 0.021373537625650984, 'spam': 4.804230149739866e-08}\n",
      "für {'ham': 0.9999977522582199, 'spam': 2.247741780146567e-06}\n",
      "{'ham': 0.012692022239750285, 'spam': 4.529910883003964e-10}\n",
      "den {'ham': 0.9999999643089916, 'spam': 3.569100838115142e-08}\n",
      "{'ham': 0.0006680026481689992, 'spam': 7.192867468994644e-12}\n",
      "tipp {'ham': 0.9999999892322772, 'spam': 1.0767722869452015e-08}\n",
      "{'ham': 0.022044087938988075, 'spam': 2.170036853980656e-12}\n",
      "mit {'ham': 0.9999999999015591, 'spam': 9.84407637899602e-11}\n",
      "{'ham': 0.00033400133597246464, 'spam': 1.983892861546961e-14}\n",
      "pywin32 {'ham': 0.9999999999406023, 'spam': 5.939775227703508e-11}\n",
      "{'ham': 0.05744822978950688, 'spam': 1.1970526456476237e-14}\n",
      "ich {'ham': 0.9999999999997917, 'spam': 2.0837067565587899e-13}\n",
      "{'ham': 0.000668002672010549, 'spam': 4.199328409026179e-17}\n",
      "nutze {'ham': 0.9999999999999372, 'spam': 6.286394628313103e-14}\n",
      "{'ham': 0.0006680026720106461, 'spam': 1.2669074220703554e-17}\n",
      "auto {'ham': 0.999999999999981, 'spam': 1.896560410839405e-14}\n",
      "{'ham': 0.0003340013360053377, 'spam': 3.822169308422824e-18}\n",
      "py {'ham': 0.9999999999999886, 'spam': 1.1443574909418021e-14}\n",
      "{'ham': 0.001336005344021361, 'spam': 4.114336484966092e-15}\n",
      "to {'ham': 0.9999999999969205, 'spam': 3.079580858987671e-12}\n",
      "{'ham': 0.00033400133600431547, 'spam': 6.206329824642626e-16}\n",
      "exe {'ham': 0.9999999999981418, 'spam': 1.8581751495002715e-12}\n",
      "{'ham': 0.00200400801602834, 'spam': 3.7448108615483106e-16}\n",
      "damit {'ham': 0.9999999999998133, 'spam': 1.8686606199157305e-13}\n",
      "{'ham': 0.002672010688042253, 'spam': 3.765942402087325e-17}\n",
      "meine {'ham': 0.9999999999999858, 'spam': 1.4094039439814245e-14}\n",
      "{'ham': 0.0003340013360053393, 'spam': 2.8403948891201625e-18}\n",
      "kollegen {'ham': 0.9999999999999916, 'spam': 8.504142298025816e-15}\n",
      "{'ham': 0.02471609886439525, 'spam': 1.7138537480906523e-18}\n",
      "nicht {'ham': 1.0, 'spam': 6.934159624031698e-17}\n",
      "{'ham': 0.0026720106880427524, 'spam': 1.3974525642949815e-20}\n",
      "erst {'ham': 0.9999999999999999, 'spam': 5.229966221873968e-18}\n",
      "{'ham': 0.011356045424181695, 'spam': 2.972290355841312e-19}\n",
      "python {'ham': 1.0, 'spam': 2.6173639192320266e-17}\n",
      "{'ham': 0.00033400133600534405, 'spam': 5.274816443434153e-21}\n",
      "installieren {'ham': 0.9999999999999999, 'spam': 1.5792800431641852e-17}\n",
      "{'ham': 0.002672010688042752, 'spam': 3.182748978565468e-21}\n",
      "müssen {'ham': 1.0, 'spam': 1.1911438052281265e-18}\n",
      "{'ham': 0.05744822979291917, 'spam': 2.400531651003883e-22}\n",
      "ich {'ham': 1.0, 'spam': 4.178599862270712e-21}\n",
      "{'ham': 0.014696058784235137, 'spam': 8.421200851009094e-25}\n",
      "habe {'ham': 1.0, 'spam': 5.730244397254824e-23}\n",
      "{'ham': 0.014028056112224449, 'spam': 1.1548255536587716e-26}\n",
      "ein {'ham': 1.0, 'spam': 8.232256446796102e-25}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.6590601464724107e-28}\n",
      "pip {'ham': 0.9999999999999999, 'spam': 4.967226078538397e-25}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.0010532201810555e-28}\n",
      "update {'ham': 1.0, 'spam': 2.9971533412220807e-25}\n",
      "{'ham': 0.0013360053440213762, 'spam': 6.040212295892948e-29}\n",
      "gemacht {'ham': 0.9999999999999999, 'spam': 4.521098903475871e-26}\n",
      "{'ham': 0.03406813627254508, 'spam': 9.111444787335492e-30}\n",
      "und {'ham': 1.0, 'spam': 2.6744770287531833e-28}\n",
      "{'ham': 0.00033400133600534405, 'spam': 5.38991742997417e-32}\n",
      "plötzlich {'ham': 0.9999999999999999, 'spam': 1.6137412785342664e-28}\n",
      "{'ham': 0.001336005344021376, 'spam': 3.2521992715321775e-32}\n",
      "konnte {'ham': 1.0, 'spam': 2.4342711547418354e-29}\n",
      "{'ham': 0.05744822979291917, 'spam': 4.9058265915796765e-33}\n",
      "ich {'ham': 1.0, 'spam': 8.539560939063693e-32}\n",
      "{'ham': 0.024716098864395457, 'spam': 1.720991724922147e-35}\n",
      "nicht {'ham': 1.0, 'spam': 6.963039492455281e-34}\n",
      "{'ham': 0.005344021376085505, 'spam': 1.4032727715548732e-37}\n",
      "mehr {'ham': 0.9999999999999999, 'spam': 2.6258741737720563e-35}\n",
      "{'ham': 0.0387441549766199, 'spam': 5.2919672990166395e-39}\n",
      "die {'ham': 1.0, 'spam': 1.365875008039295e-37}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.7526703104379185e-41}\n",
      "exe {'ham': 0.9999999999999999, 'spam': 8.241494909451127e-38}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.660921989006676e-41}\n",
      "datei {'ham': 1.0, 'spam': 4.972800435085989e-38}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.0021766294006427e-41}\n",
      "nutzen {'ham': 0.9999999999999999, 'spam': 3.0005168284255237e-38}\n",
      "{'ham': 0.057448229792919164, 'spam': 6.046990786830964e-42}\n",
      "ich {'ham': 1.0, 'spam': 1.0525982799867388e-40}\n",
      "{'ham': 0.014696058784235137, 'spam': 2.1213185811905255e-44}\n",
      "habe {'ham': 1.0, 'spam': 1.4434608709282803e-42}\n",
      "{'ham': 0.012024048096192385, 'spam': 2.9090303726889972e-46}\n",
      "eine {'ham': 1.0, 'spam': 2.4193435932863497e-44}\n",
      "{'ham': 0.00033400133600534405, 'spam': 4.875742832096634e-48}\n",
      "erzeugt {'ham': 0.9999999999999999, 'spam': 1.459797403929732e-44}\n",
      "{'ham': 0.001336005344021376, 'spam': 2.941953655642346e-48}\n",
      "bekommen {'ham': 1.0, 'spam': 2.2020523112482962e-45}\n",
      "{'ham': 0.014696058784235137, 'spam': 4.437832146812367e-49}\n",
      "da {'ham': 1.0, 'spam': 3.019743056262779e-47}\n",
      "{'ham': 0.013360053440213761, 'spam': 6.085737719191412e-51}\n",
      "es {'ham': 1.0, 'spam': 4.555174682814772e-49}\n",
      "{'ham': 0.007348029392117568, 'spam': 9.180118264439283e-53}\n",
      "im {'ham': 1.0, 'spam': 1.2493306401696006e-50}\n",
      "{'ham': 0.00033400133600534405, 'spam': 5.035593067995166e-54}\n",
      "visual {'ham': 0.9999999999999999, 'spam': 1.5076565645577525e-50}\n",
      "{'ham': 0.000334001336005344, 'spam': 2.4307240057359977e-53}\n",
      "studio {'ham': 1.0, 'spam': 7.277587673173578e-50}\n",
      "{'ham': 0.004676018704074816, 'spam': 3.2266612013264557e-52}\n",
      "code {'ham': 1.0, 'spam': 6.900445454836721e-50}\n",
      "{'ham': 0.0006680026720106881, 'spam': 1.390658092470117e-53}\n",
      "funktioniert {'ham': 0.9999999999999999, 'spam': 2.081815164427765e-50}\n",
      "{'ham': 0.0046760187040748155, 'spam': 4.1955162523735695e-54}\n",
      "hat {'ham': 1.0, 'spam': 8.972411185433193e-52}\n",
      "{'ham': 0.014696058784235137, 'spam': 1.8082247451497768e-55}\n",
      "habe {'ham': 1.0, 'spam': 1.2304147470405526e-53}\n",
      "{'ham': 0.05744822979291917, 'spam': 2.4796750242655234e-57}\n",
      "ich {'ham': 1.0, 'spam': 4.316364548052894e-56}\n",
      "{'ham': 0.01002004008016032, 'spam': 8.698840282250894e-60}\n",
      "wie {'ham': 0.9999999999999999, 'spam': 8.681442601686392e-58}\n",
      "{'ham': 0.011356045424181695, 'spam': 1.7495853691427636e-61}\n",
      "immer {'ham': 1.0, 'spam': 1.5406642927098339e-59}\n",
      "{'ham': 0.038744154976619906, 'spam': 3.104926023195957e-63}\n",
      "die {'ham': 1.0, 'spam': 8.013921132283358e-62}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.6150586723666583e-65}\n",
      "alte {'ham': 0.9999999999999999, 'spam': 4.835485665065774e-62}\n",
      "{'ham': 0.000334001336005344, 'spam': 9.74503358538044e-66}\n",
      "exe {'ham': 1.0, 'spam': 2.9176630554629043e-62}\n",
      "{'ham': 0.0006680026720106881, 'spam': 5.880014218990134e-66}\n",
      "gleich {'ham': 0.9999999999999999, 'spam': 8.802381285828229e-63}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.7739583405538552e-66}\n",
      "überschrieben {'ham': 1.0, 'spam': 5.311231271618243e-63}\n",
      "{'ham': 0.05744822979291917, 'spam': 1.0703811510717943e-66}\n",
      "ich {'ham': 1.0, 'spam': 1.8632099804121815e-65}\n",
      "{'ham': 0.014696058784235137, 'spam': 3.7549576388798503e-69}\n",
      "habe {'ham': 1.0, 'spam': 2.555077993365062e-67}\n",
      "{'ham': 0.0006680026720106881, 'spam': 5.149290595254055e-71}\n",
      "drei {'ham': 0.9999999999999999, 'spam': 7.708488021095318e-68}\n",
      "{'ham': 0.000668002672010688, 'spam': 1.553504236415824e-71}\n",
      "stunden {'ham': 1.0, 'spam': 2.3255958419144887e-68}\n",
      "{'ham': 0.00033400133600534405, 'spam': 4.686811450855479e-72}\n",
      "geschwitzt {'ham': 0.9999999999999999, 'spam': 1.4032313483861302e-68}\n",
      "{'ham': 0.005344021376085504, 'spam': 2.8279551559575375e-72}\n",
      "um {'ham': 1.0, 'spam': 5.291811085585543e-70}\n",
      "{'ham': 0.012024048096192385, 'spam': 1.0664673691224392e-73}\n",
      "eine {'ham': 1.0, 'spam': 8.869453619868287e-72}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.7874755380629357e-75}\n",
      "funktionierende {'ham': 0.9999999999999999, 'spam': 5.351701760960428e-72}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.0785372351794496e-75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version {'ham': 1.0, 'spam': 3.2291404821272726e-72}\n",
      "{'ham': 0.02404809619238477, 'spam': 1.2885324777533253e-73}\n",
      "in {'ham': 1.0, 'spam': 5.358147553324245e-72}\n",
      "{'ham': 0.0013360053440213762, 'spam': 1.0798362662886428e-75}\n",
      "meinen {'ham': 0.9999999999999999, 'spam': 8.08257445317049e-73}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.6288944887485872e-76}\n",
      "ordnern {'ham': 1.0, 'spam': 4.8769100993132705e-73}\n",
      "{'ham': 0.02738810955243821, 'spam': 9.828516927273822e-77}\n",
      "zu {'ham': 0.9999999999999999, 'spam': 3.5886072780802217e-75}\n",
      "{'ham': 0.000668002672010688, 'spam': 7.232179117453087e-79}\n",
      "finden {'ham': 1.0, 'spam': 1.0826572138827273e-75}\n",
      "{'ham': 0.05744822979291917, 'spam': 2.1818968437781688e-79}\n",
      "ich {'ham': 1.0, 'spam': 3.798022761785952e-78}\n",
      "{'ham': 0.002004008016032064, 'spam': 7.654217577158307e-82}\n",
      "werde {'ham': 1.0, 'spam': 3.8194545710019956e-79}\n",
      "{'ham': 0.013360053440213761, 'spam': 7.697409453853276e-83}\n",
      "es {'ham': 1.0, 'spam': 5.7615109762091765e-81}\n",
      "{'ham': 0.004008016032064128, 'spam': 1.1611267586072505e-84}\n",
      "nach {'ham': 1.0, 'spam': 2.8970112627250904e-82}\n",
      "{'ham': 0.0013360053440213762, 'spam': 5.8383943222996586e-86}\n",
      "meinem {'ham': 0.9999999999999999, 'spam': 4.370038150241294e-83}\n",
      "{'ham': 0.000334001336005344, 'spam': 8.807009573239206e-87}\n",
      "urlaub {'ham': 1.0, 'spam': 2.6368186662278187e-83}\n",
      "{'ham': 0.0013360053440213762, 'spam': 5.314023914203585e-87}\n",
      "testen {'ham': 0.9999999999999999, 'spam': 3.9775468997813825e-84}\n",
      "{'ham': 0.001336005344021376, 'spam': 8.016015517495733e-88}\n",
      "hoffe {'ham': 1.0, 'spam': 5.999987614845557e-85}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.2091873468048282e-88}\n",
      "euer {'ham': 0.9999999999999999, 'spam': 3.6203069163336554e-85}\n",
      "{'ham': 0.000668002672010688, 'spam': 7.296063918447512e-89}\n",
      "tipp {'ham': 1.0, 'spam': 1.0922207685915928e-85}\n",
      "{'ham': 0.0006680026720106881, 'spam': 2.2011704324699574e-89}\n",
      "funktioniert {'ham': 0.9999999999999999, 'spam': 3.295152137407526e-86}\n",
      "{'ham': 0.014696058784235135, 'spam': 6.6407741584190365e-90}\n",
      "da {'ham': 1.0, 'spam': 4.518744961433318e-88}\n",
      "{'ham': 0.0026720106880427524, 'spam': 9.10670084932148e-92}\n",
      "meine {'ham': 0.9999999999999999, 'spam': 3.408182792858563e-89}\n",
      "{'ham': 0.000334001336005344, 'spam': 6.868566692580741e-93}\n",
      "kollegen {'ham': 1.0, 'spam': 2.056448867758674e-89}\n",
      "{'ham': 0.002004008016032064, 'spam': 4.1443951385704844e-93}\n",
      "sonst {'ham': 1.0, 'spam': 2.068053174146672e-90}\n",
      "{'ham': 0.011356045424181697, 'spam': 1.1753143795029456e-91}\n",
      "python {'ham': 1.0, 'spam': 1.0349680153622998e-89}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.085788019674123e-93}\n",
      "installieren {'ham': 0.9999999999999999, 'spam': 6.2448493309043235e-90}\n",
      "{'ham': 0.002672010688042752, 'spam': 1.2585347301298517e-93}\n",
      "müssen {'ham': 1.0, 'spam': 4.710066227510971e-91}\n",
      "{'ham': 0.03406813627254509, 'spam': 9.492273735411067e-95}\n",
      "und {'ham': 1.0, 'spam': 2.786261525864778e-93}\n",
      "{'ham': 0.012024048096192385, 'spam': 5.615198560791572e-97}\n",
      "eine {'ham': 1.0, 'spam': 4.6699734697249915e-95}\n",
      "{'ham': 0.00033400133600534405, 'spam': 9.411474142936299e-99}\n",
      "pyw {'ham': 0.9999999999999999, 'spam': 2.8177953583951275e-95}\n",
      "{'ham': 0.000334001336005344, 'spam': 5.678749210792277e-99}\n",
      "starten {'ham': 1.0, 'spam': 1.700217513711208e-95}\n",
      "{'ham': 0.0026720106880427524, 'spam': 3.4264762468988477e-99}\n",
      "müssen {'ham': 0.9999999999999999, 'spam': 1.2823587354018935e-96}\n",
      "{'ham': 0.010020040080160319, 'spam': 2.5843585961344085e-100}\n",
      "bei {'ham': 1.0, 'spam': 2.5791898789421402e-98}\n",
      "{'ham': 0.02137608550434202, 'spam': 5.1978836738052e-102}\n",
      "der {'ham': 0.9999999999999999, 'spam': 2.431634956151995e-100}\n",
      "{'ham': 0.000334001336005344, 'spam': 4.900513817315588e-104}\n",
      "exe {'ham': 1.0, 'spam': 1.4672138369042874e-100}\n",
      "{'ham': 0.002004008016032064, 'spam': 2.956900114680144e-104}\n",
      "können {'ham': 1.0, 'spam': 1.475493157225392e-101}\n",
      "{'ham': 0.004008016032064128, 'spam': 2.9735855647428296e-105}\n",
      "sie {'ham': 1.0, 'spam': 7.419095984033361e-103}\n",
      "{'ham': 0.0006680026720106881, 'spam': 1.4951825844484807e-106}\n",
      "wenigstens {'ham': 0.9999999999999999, 'spam': 2.2382883289193754e-103}\n",
      "{'ham': 0.000668002672010688, 'spam': 4.510859187665005e-107}\n",
      "nichts {'ham': 1.0, 'spam': 6.752756203934513e-104}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.360894035456371e-107}\n",
      "kaputt {'ham': 0.9999999999999999, 'spam': 4.0745167421563746e-104}\n",
      "{'ham': 0.0046760187040748155, 'spam': 8.211440431592855e-108}\n",
      "machen {'ham': 1.0, 'spam': 1.7560751894420723e-105}\n",
      "{'ham': 0.0033400133600534404, 'spam': 1.2032760266229435e-107}\n",
      "also {'ham': 1.0, 'spam': 3.6026084237090925e-105}\n",
      "{'ham': 0.006012024048096192, 'spam': 7.260395855923201e-109}\n",
      "vielen {'ham': 1.0, 'spam': 1.2076458440352258e-106}\n",
      "{'ham': 0.006680026720106881, 'spam': 2.4337884805224222e-110}\n",
      "dank {'ham': 1.0, 'spam': 3.643381355342065e-108}\n",
      "{'ham': 0.0006680026720106881, 'spam': 7.342566213909846e-112}\n",
      "bleibt {'ham': 0.9999999999999999, 'spam': 1.0991821622223038e-108}\n",
      "{'ham': 0.000668002672010688, 'spam': 2.215199843253333e-112}\n",
      "gesund {'ham': 1.0, 'spam': 3.31615416535024e-109}\n",
      "{'ham': 0.0006680026720106881, 'spam': 6.683099889863443e-113}\n",
      "toller {'ham': 0.9999999999999999, 'spam': 1.0004600535125573e-109}\n",
      "{'ham': 0.004008016032064127, 'spam': 5.6858068337473026e-111}\n",
      "podcast {'ham': 1.0, 'spam': 1.4186088050199526e-108}\n",
      "{'ham': 0.028724114896459586, 'spam': 2.8589455965738666e-112}\n",
      "auch {'ham': 1.0, 'spam': 9.95311990249088e-111}\n",
      "{'ham': 0.008016032064128256, 'spam': 2.0058685817192422e-114}\n",
      "wenn {'ham': 1.0, 'spam': 2.502321055694755e-112}\n",
      "{'ham': 0.05744822979291917, 'spam': 5.0429686733066407e-116}\n",
      "ich {'ham': 1.0, 'spam': 8.778283841790746e-115}\n",
      "{'ham': 0.024716098864395457, 'spam': 1.7691019431259062e-118}\n",
      "nicht {'ham': 1.0, 'spam': 7.157690834755356e-117}\n",
      "{'ham': 0.011356045424181697, 'spam': 1.4425011758878187e-120}\n",
      "immer {'ham': 1.0, 'spam': 1.2702495648847439e-118}\n",
      "{'ham': 0.002004008016032064, 'spam': 2.5599547861441835e-122}\n",
      "alles {'ham': 1.0, 'spam': 1.2774174382859477e-119}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.574400318996267e-123}\n",
      "verstehe {'ham': 0.9999999999999999, 'spam': 7.707754555074822e-120}\n",
      "{'ham': 0.002672010688042752, 'spam': 1.5533564198054862e-123}\n",
      "frage {'ham': 1.0, 'spam': 5.813436401122033e-121}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.1715913746719131e-124}\n",
      "würdet {'ham': 0.9999999999999999, 'spam': 3.5077445757677075e-121}\n",
      "{'ham': 0.008684034736138943, 'spam': 7.069215186956283e-125}\n",
      "ihr {'ham': 1.0, 'spam': 8.140473180671968e-123}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.640562914282944e-126}\n",
      "tkinter {'ham': 0.9999999999999999, 'spam': 4.911845365363134e-123}\n",
      "{'ham': 0.008016032064128254, 'spam': 9.898922542045817e-127}\n",
      "oder {'ham': 1.0, 'spam': 1.2348905871202161e-124}\n",
      "{'ham': 0.005344021376085505, 'spam': 2.4886952582027735e-128}\n",
      "django {'ham': 0.9999999999999999, 'spam': 4.656971001911939e-126}\n",
      "{'ham': 0.000668002672010688, 'spam': 9.385270056251389e-130}\n",
      "empfehlen {'ham': 1.0, 'spam': 1.4049749274208332e-126}\n",
      "{'ham': 0.008016032064128256, 'spam': 2.8314690193890233e-130}\n",
      "wenn {'ham': 1.0, 'spam': 3.532257601687807e-128}\n",
      "{'ham': 0.018036072144288578, 'spam': 7.118616690221296e-132}\n",
      "man {'ham': 1.0, 'spam': 3.9468774760226964e-130}\n",
      "{'ham': 0.014028056112224449, 'spam': 7.954206924672907e-134}\n",
      "ein {'ham': 1.0, 'spam': 5.67021322201683e-132}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.1427273724338634e-135}\n",
      "cockpit {'ham': 0.9999999999999999, 'spam': 3.421325753066986e-132}\n",
      "{'ham': 0.000668002672010688, 'spam': 6.895053915894773e-136}\n",
      "bauen {'ham': 1.0, 'spam': 1.0321895712094477e-132}\n",
      "{'ham': 0.0033400133600534404, 'spam': 2.0801885755934052e-136}\n",
      "möchte {'ham': 1.0, 'spam': 6.228084595326655e-134}\n",
      "{'ham': 0.002004008016032064, 'spam': 1.2551561054668793e-137}\n",
      "damit {'ham': 1.0, 'spam': 6.263228966279728e-135}\n",
      "{'ham': 0.038744154976619906, 'spam': 1.2622388081982524e-138}\n",
      "die {'ham': 1.0, 'spam': 3.2578818894358343e-137}\n",
      "{'ham': 0.00033400133600534405, 'spam': 6.565662816275361e-141}\n",
      "kollegen {'ham': 0.9999999999999999, 'spam': 1.9657594471928427e-137}\n",
      "{'ham': 0.0020040080160320635, 'spam': 3.9616272615736454e-141}\n",
      "damit {'ham': 1.0, 'spam': 1.97685200352525e-138}\n",
      "{'ham': 0.0013360053440213762, 'spam': 3.983982272320133e-142}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arbeiten {'ham': 0.9999999999999999, 'spam': 2.9820107308316193e-139}\n",
      "{'ham': 0.0020040080160320635, 'spam': 6.009695144763441e-143}\n",
      "können {'ham': 1.0, 'spam': 2.998837877236958e-140}\n",
      "{'ham': 0.05744822979291917, 'spam': 6.043607168957997e-144}\n",
      "ich {'ham': 1.0, 'spam': 1.0520092944104792e-142}\n",
      "{'ham': 0.014696058784235137, 'spam': 2.1201315888965723e-146}\n",
      "habe {'ham': 1.0, 'spam': 1.4426531766264405e-144}\n",
      "{'ham': 0.0026720106880427524, 'spam': 2.9074026131125362e-148}\n",
      "eure {'ham': 0.9999999999999999, 'spam': 1.0880954279573666e-145}\n",
      "{'ham': 0.005344021376085504, 'spam': 2.1928565658149267e-149}\n",
      "django {'ham': 1.0, 'spam': 4.1033828487811823e-147}\n",
      "{'ham': 0.008684034736138945, 'spam': 8.269614769812943e-151}\n",
      "folge {'ham': 1.0, 'spam': 9.522779469546136e-149}\n",
      "{'ham': 0.0006680026720106881, 'spam': 1.919141368308371e-152}\n",
      "zwar {'ham': 0.9999999999999999, 'spam': 2.8729546283576308e-149}\n",
      "{'ham': 0.000334001336005344, 'spam': 5.789912592417635e-153}\n",
      "gehört {'ham': 1.0, 'spam': 1.7334998301698403e-149}\n",
      "{'ham': 0.014696058784235137, 'spam': 3.493550645243532e-153}\n",
      "aber {'ham': 1.0, 'spam': 2.3772024163316216e-151}\n",
      "{'ham': 0.01002004008016032, 'spam': 4.790815026867436e-155}\n",
      "war {'ham': 0.9999999999999999, 'spam': 4.7812333968137e-153}\n",
      "{'ham': 0.0060120240480961915, 'spam': 9.635698099181178e-157}\n",
      "dann {'ham': 1.0, 'spam': 1.6027377838304696e-154}\n",
      "{'ham': 0.0006680026720106881, 'spam': 3.2300237481468557e-158}\n",
      "fachlich {'ham': 0.9999999999999999, 'spam': 4.835345550975842e-155}\n",
      "{'ham': 0.001336005344021376, 'spam': 9.744751211156475e-159}\n",
      "schnell {'ham': 1.0, 'spam': 7.293946281550622e-156}\n",
      "{'ham': 0.002004008016032064, 'spam': 1.4699609596031082e-159}\n",
      "raus {'ham': 1.0, 'spam': 7.33510518841951e-157}\n",
      "{'ham': 0.006680026720106881, 'spam': 1.4782557816242464e-160}\n",
      "wir {'ham': 1.0, 'spam': 2.2129489050914968e-158}\n",
      "{'ham': 0.002004008016032064, 'spam': 4.459792231139655e-162}\n",
      "haben {'ham': 1.0, 'spam': 2.2254363233386882e-159}\n",
      "{'ham': 0.0033400133600534404, 'spam': 4.4849583299852646e-163}\n",
      "keine {'ham': 1.0, 'spam': 1.342796523997588e-160}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.7061598629536236e-164}\n",
      "netzlaufwerke {'ham': 0.9999999999999999, 'spam': 8.102242629683148e-161}\n",
      "{'ham': 0.005344021376085504, 'spam': 1.6328582486261886e-164}\n",
      "mehr {'ham': 1.0, 'spam': 3.055485997741756e-162}\n",
      "{'ham': 0.0013360053440213762, 'spam': 6.157771055505352e-166}\n",
      "sondern {'ham': 0.9999999999999999, 'spam': 4.6090916350457555e-163}\n",
      "{'ham': 0.008684034736138943, 'spam': 9.288777982760492e-167}\n",
      "nur {'ham': 1.0, 'spam': 1.0696385107840353e-164}\n",
      "{'ham': 0.014696058784235137, 'spam': 2.1556600378557745e-168}\n",
      "noch {'ham': 1.0, 'spam': 1.4668286712136793e-166}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.9561238839453432e-170}\n",
      "onedrive {'ham': 0.9999999999999999, 'spam': 8.850634908532356e-167}\n",
      "{'ham': 0.03406813627254508, 'spam': 1.78368297229592e-170}\n",
      "und {'ham': 1.0, 'spam': 5.235634136327437e-169}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.0551459363819906e-172}\n",
      "sharepoints {'ham': 0.9999999999999999, 'spam': 3.1591069335276795e-169}\n",
      "{'ham': 0.057448229792919164, 'spam': 6.3666000272625545e-173}\n",
      "ich {'ham': 1.0, 'spam': 1.1082325861409356e-171}\n",
      "{'ham': 0.014696058784235137, 'spam': 2.2334393110458196e-175}\n",
      "habe {'ham': 1.0, 'spam': 1.5197539311979965e-173}\n",
      "{'ham': 0.014028056112224449, 'spam': 3.0627850286134553e-177}\n",
      "ein {'ham': 1.0, 'spam': 2.1833281846830206e-175}\n",
      "{'ham': 0.00033400133600534405, 'spam': 4.4000971073821457e-179}\n",
      "3800 {'ham': 0.9999999999999999, 'spam': 1.317389073950214e-175}\n",
      "{'ham': 0.000334001336005344, 'spam': 2.6549558120721767e-179}\n",
      "zeilen {'ham': 1.0, 'spam': 7.948937701344099e-176}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.6019624549262595e-179}\n",
      "langes {'ham': 0.9999999999999999, 'spam': 4.79627559004922e-176}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.933202575594204e-179}\n",
      "script {'ham': 1.0, 'spam': 5.788008511329048e-176}\n",
      "{'ham': 0.002004008016032064, 'spam': 1.1664668503283048e-179}\n",
      "geschrieben {'ham': 1.0, 'spam': 5.8206695831382415e-177}\n",
      "{'ham': 0.01002004008016032, 'spam': 1.642268725593216e-179}\n",
      "was {'ham': 0.9999999999999999, 'spam': 1.6389841881420297e-177}\n",
      "{'ham': 0.000334001336005344, 'spam': 3.3030717213664444e-181}\n",
      "tkinter {'ham': 1.0, 'spam': 9.889396733771136e-178}\n",
      "{'ham': 0.0006680026720106881, 'spam': 1.9930263469913616e-181}\n",
      "nutzt {'ham': 0.9999999999999999, 'spam': 2.983560441446068e-178}\n",
      "{'ham': 0.011356045424181695, 'spam': 6.012818301987239e-182}\n",
      "kann {'ham': 1.0, 'spam': 5.294817057691117e-180}\n",
      "{'ham': 0.018036072144288578, 'spam': 1.0670731676120751e-183}\n",
      "man {'ham': 1.0, 'spam': 5.916327895982505e-182}\n",
      "{'ham': 0.005344021376085505, 'spam': 1.192327266421303e-185}\n",
      "django {'ham': 0.9999999999999999, 'spam': 2.2311423972908628e-183}\n",
      "{'ham': 0.00668002672010688, 'spam': 4.496457874427374e-187}\n",
      "einfach {'ham': 1.0, 'spam': 6.73119743801778e-185}\n",
      "{'ham': 0.020708082832331328, 'spam': 2.5503126125500653e-186}\n",
      "so {'ham': 1.0, 'spam': 1.2315541874153059e-184}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.481971357144913e-188}\n",
      "anderen {'ham': 0.9999999999999999, 'spam': 7.431022243291869e-185}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.4975861030414892e-188}\n",
      "bereitstellen {'ham': 1.0, 'spam': 4.4837727925062194e-185}\n",
      "{'ham': 0.008016032064128256, 'spam': 9.036220863575613e-189}\n",
      "oder {'ham': 1.0, 'spam': 1.127268552731058e-186}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.2718028067937485e-190}\n",
      "benötigt {'ham': 0.9999999999999999, 'spam': 6.801777603540482e-187}\n",
      "{'ham': 0.018036072144288574, 'spam': 1.3707733985369774e-190}\n",
      "man {'ham': 1.0, 'spam': 7.600176954110575e-189}\n",
      "{'ham': 0.004676018704074816, 'spam': 1.5316761294055977e-192}\n",
      "einen {'ham': 1.0, 'spam': 3.2755988081716856e-190}\n",
      "{'ham': 0.0013360053440213762, 'spam': 6.601368013244026e-194}\n",
      "server {'ham': 0.9999999999999999, 'spam': 4.941123957913153e-191}\n",
      "{'ham': 0.000668002672010688, 'spam': 9.95792816991768e-195}\n",
      "wo {'ham': 1.0, 'spam': 1.4907018470366768e-191}\n",
      "{'ham': 0.047428189712758854, 'spam': 3.0042358868131336e-195}\n",
      "das {'ham': 1.0, 'spam': 6.334283271210226e-194}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.2765584988331774e-197}\n",
      "laufen {'ham': 0.9999999999999999, 'spam': 3.8220161455065327e-194}\n",
      "{'ham': 0.0060120240480961915, 'spam': 7.702571836974068e-198}\n",
      "muss {'ham': 1.0, 'spam': 1.2811944488833537e-195}\n",
      "{'ham': 0.008016032064128256, 'spam': 2.582012190413853e-199}\n",
      "wenn {'ham': 1.0, 'spam': 3.2210602075412815e-197}\n",
      "{'ham': 0.015364061456245824, 'spam': 6.491455476705525e-201}\n",
      "ja {'ham': 1.0, 'spam': 4.225090803751379e-199}\n",
      "{'ham': 0.006012024048096192, 'spam': 8.514894808043892e-203}\n",
      "dann {'ham': 1.0, 'spam': 1.4163108364046343e-200}\n",
      "{'ham': 0.006012024048096192, 'spam': 2.854314462725986e-204}\n",
      "muss {'ham': 1.0, 'spam': 4.747676389667557e-202}\n",
      "{'ham': 0.05744822979291917, 'spam': 9.568070112187742e-206}\n",
      "ich {'ham': 1.0, 'spam': 1.665511739295936e-204}\n",
      "{'ham': 0.01002004008016032, 'spam': 3.356533130382781e-208}\n",
      "bei {'ham': 0.9999999999999999, 'spam': 3.3498200641220156e-206}\n",
      "{'ham': 0.000334001336005344, 'spam': 6.750947327936347e-210}\n",
      "tkinter {'ham': 1.0, 'spam': 2.0212336299841427e-206}\n",
      "{'ham': 0.00033400133600534405, 'spam': 4.0734252921889216e-210}\n",
      "bleiben {'ham': 0.9999999999999999, 'spam': 1.219583532481363e-206}\n",
      "{'ham': 0.010020040080160319, 'spam': 3.440985379834559e-209}\n",
      "was {'ham': 1.0, 'spam': 3.4341034090748905e-207}\n",
      "{'ham': 0.028724114896459586, 'spam': 6.920804935660803e-211}\n",
      "auch {'ham': 1.0, 'spam': 2.409405811321912e-209}\n",
      "{'ham': 0.00033400133600534405, 'spam': 9.711430114155227e-212}\n",
      "okay {'ham': 0.9999999999999999, 'spam': 2.9076021761780748e-208}\n",
      "{'ham': 0.02538410153640614, 'spam': 5.859738363921956e-212}\n",
      "ist {'ham': 0.9999999999999999, 'spam': 2.3084285081029392e-210}\n",
      "{'ham': 0.014696058784235135, 'spam': 4.652213841400523e-214}\n",
      "aber {'ham': 1.0, 'spam': 3.1656200548075384e-212}\n",
      "{'ham': 0.018036072144288578, 'spam': 6.379726027423496e-216}\n",
      "man {'ham': 1.0, 'spam': 3.5372036529825826e-214}\n",
      "{'ham': 0.0013360053440213762, 'spam': 8.126586385328787e-216}\n",
      "will {'ham': 0.9999999999999999, 'spam': 6.082749909418596e-213}\n",
      "{'ham': 0.015364061456245822, 'spam': 1.2258665677989915e-216}\n",
      "ja {'ham': 1.0, 'spam': 7.978792399978655e-215}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham': 0.047428189712758854, 'spam': 1.6079791213177458e-218}\n",
      "das {'ham': 1.0, 'spam': 3.390344710722064e-217}\n",
      "{'ham': 0.00033400133600534405, 'spam': 6.832617313023104e-221}\n",
      "tool {'ham': 0.9999999999999999, 'spam': 2.045685623519117e-217}\n",
      "{'ham': 0.028724114896459582, 'spam': 4.122703795886975e-221}\n",
      "auch {'ham': 1.0, 'spam': 1.4352761819634424e-219}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.8925356347509924e-223}\n",
      "optisch {'ham': 0.9999999999999999, 'spam': 8.66025169044447e-220}\n",
      "{'ham': 0.000334001336005344, 'spam': 1.7453147300371768e-223}\n",
      "anheben {'ham': 1.0, 'spam': 5.225472301731308e-220}\n",
      "{'ham': 0.0033400133600534404, 'spam': 3.580533217631287e-222}\n",
      "also {'ham': 1.0, 'spam': 1.0720116453588071e-219}\n",
      "{'ham': 0.01002004008016032, 'spam': 2.1604426548948148e-223}\n",
      "wie {'ham': 0.9999999999999999, 'spam': 2.156121769585025e-221}\n",
      "{'ham': 0.002672010688042752, 'spam': 4.3452675727227427e-225}\n",
      "gesagt {'ham': 1.0, 'spam': 1.6262163890914868e-222}\n",
      "{'ham': 0.00033400133600534405, 'spam': 3.2773405664882847e-226}\n",
      "dankeschön {'ham': 0.9999999999999999, 'spam': 9.812357656065922e-223}\n",
      "{'ham': 0.021376085504342016, 'spam': 3.9550010705626455e-226}\n",
      "für {'ham': 1.0, 'spam': 1.850198938322588e-224}\n",
      "{'ham': 0.038744154976619906, 'spam': 3.7287362723147686e-228}\n",
      "die {'ham': 1.0, 'spam': 9.623996895957256e-227}\n",
      "{'ham': 0.00033400133600534405, 'spam': 1.9395398822969078e-230}\n",
      "tollen {'ham': 0.9999999999999999, 'spam': 5.806982407596941e-227}\n",
      "{'ham': 0.002672010688042752, 'spam': 1.1702906907692344e-230}\n",
      "folgen {'ham': 1.0, 'spam': 4.37981291020386e-228}\n",
      "{'ham': 0.05744822979291917, 'spam': 8.826708807343532e-232}\n",
      "ich {'ham': 1.0, 'spam': 1.53646314937131e-230}\n",
      "{'ham': 0.00033400133600534405, 'spam': 3.096459390107437e-234}\n",
      "lerne {'ham': 0.9999999999999999, 'spam': 9.270799413981664e-231}\n",
      "{'ham': 0.011356045424181695, 'spam': 1.8683594143453577e-234}\n",
      "immer {'ham': 1.0, 'spam': 1.64525531957353e-232}\n",
      "{'ham': 0.002004008016032064, 'spam': 3.315710035416223e-236}\n",
      "etwas {'ham': 1.0, 'spam': 1.6545393076726954e-233}\n",
      "{'ham': 0.0026720106880427524, 'spam': 3.334420208933284e-237}\n",
      "dazu {'ham': 0.9999999999999999, 'spam': 1.2479067631932814e-234}\n",
      "{'ham': 0.03406813627254508, 'spam': 2.514926971368967e-238}\n",
      "und {'ham': 1.0, 'spam': 7.382050345371264e-237}\n",
      "{'ham': 0.0013360053440213762, 'spam': 1.48771671611674e-240}\n",
      "heute {'ham': 0.9999999999999999, 'spam': 1.1135559620133796e-237}\n",
      "{'ham': 0.010020040080160319, 'spam': 2.24416759776981e-241}\n",
      "war {'ham': 1.0, 'spam': 2.2396792625742707e-239}\n",
      "{'ham': 0.013360053440213761, 'spam': 4.513662359077531e-243}\n",
      "es {'ham': 1.0, 'spam': 3.378476275769532e-241}\n",
      "{'ham': 0.0033400133600534404, 'spam': 6.808698661365441e-245}\n",
      "ganz {'ham': 1.0, 'spam': 2.038524379212813e-242}\n",
      "{'ham': 0.00033400133600534405, 'spam': 4.1082716227585913e-246}\n",
      "wichtig {'ham': 0.9999999999999999, 'spam': 1.230016523853922e-242}\n",
      "{'ham': 0.022044088176352703, 'spam': 2.4788724785447845e-246}\n",
      "mit {'ham': 1.0, 'spam': 1.124506697085316e-244}\n",
      "{'ham': 0.01068804275217101, 'spam': 2.266236793803539e-248}\n",
      "dem {'ham': 0.9999999999999999, 'spam': 2.1203478002024357e-246}\n",
      "{'ham': 0.000334001336005344, 'spam': 4.2731717053656504e-250}\n",
      "pywin32 {'ham': 1.0, 'spam': 1.2793876085864759e-246}\n",
      "{'ham': 0.00033400133600534405, 'spam': 2.578370835522926e-250}\n",
      "hinweis {'ham': 0.9999999999999999, 'spam': 7.719642281555638e-247}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"for word in model.tokenize(false_positive):\\n    counts_per_label = model.word_label_counts.get(word, {})\\n    probabilities = model.update_probabilities(\\n        probabilities, counts_per_label, model.number_of_words\\n    )\\n    print(probabilities)\\n    probabilities = normalize(probabilities)\\n    print(word, probabilities)\";\n",
       "                var nbb_formatted_code = \"for word in model.tokenize(false_positive):\\n    counts_per_label = model.word_label_counts.get(word, {})\\n    probabilities = model.update_probabilities(\\n        probabilities, counts_per_label, model.number_of_words\\n    )\\n    print(probabilities)\\n    probabilities = normalize(probabilities)\\n    print(word, probabilities)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word in model.tokenize(false_positive):\n",
    "    counts_per_label = model.word_label_counts.get(word, {})\n",
    "    probabilities = model.update_probabilities(\n",
    "        probabilities, counts_per_label, model.number_of_words\n",
    "    )\n",
    "    print(probabilities)\n",
    "    probabilities = normalize(probabilities)\n",
    "    print(word, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d243357",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, message):\n",
    "        probabilities = dict(self.prior_probabilities)\n",
    "        for word in self.tokenize(message):\n",
    "            counts_per_label = self.word_label_counts.get(word, {})\n",
    "            probabilities = self.update_probabilities(\n",
    "                probabilities, counts_per_label, self.number_of_words\n",
    "            )\n",
    "        return probabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
